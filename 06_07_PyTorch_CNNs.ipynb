{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEqJ0PuNlS7i"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7iF2xh5lS7l"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import trange, tqdm\n",
        "\n",
        "import torch as tc\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6tg1MWClS7m"
      },
      "outputs": [],
      "source": [
        "# we are no longer doing the BGR to RGB conversion here\n",
        "# we'll be using PIL instead of OpenCV to load images\n",
        "def show_img(im, ax=None, figsize=(8,8), title=None):\n",
        "    if not ax: _,ax = plt.subplots(1,1,figsize=figsize)\n",
        "    if len(im.shape)==2: im = np.tile(im[:,:,None], 3)\n",
        "    ax.imshow(im);\n",
        "    ax.xaxis.set_visible(False)\n",
        "    ax.yaxis.set_visible(False)\n",
        "    if title: ax.set_title(title)\n",
        "    return ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVV2TnqylS7m"
      },
      "outputs": [],
      "source": [
        "def show_imgs(ims, rows=1, figsize=(16,8), title=[None]):\n",
        "    title = title*len(ims) if len(title) == 1 else title\n",
        "    _,ax = plt.subplots(rows, len(ims)//rows, figsize=figsize)\n",
        "    [show_img(im,ax_,title=tit) for im,ax_,tit in zip(ims,ax.flatten(),title)]\n",
        "    return ax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CCLlf-8lS7m"
      },
      "source": [
        "# Convolutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzB-VvKLlS7n"
      },
      "source": [
        "## The fully-connected layer problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozK_UFAxlS7n"
      },
      "source": [
        "Let's assume that we want to build a neural network to classify colour images of relatively high `4096x4096` resolution into one of `100` classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaycMIVvlS7n"
      },
      "outputs": [],
      "source": [
        "c, h, w = 3, 4096, 4096"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xE5yh1N-lS7o"
      },
      "outputs": [],
      "source": [
        "# batch of dummy data (BxCxHxW)\n",
        "xb = tc.randn((16, c, h, w))\n",
        "xb[0,0,:5,:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayL5AhS7lS7o"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression network - this is supposed to crash!\n",
        "net = nn.Sequential(\n",
        "    nn.Linear(c*h*w, 100),\n",
        "    nn.LogSoftmax(dim=1)\n",
        ").cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRWl2DFOlS7o"
      },
      "outputs": [],
      "source": [
        "out = net(xb.view(xb.shape[0],-1).cuda())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIjW8R-8lS7p"
      },
      "outputs": [],
      "source": [
        "c*h*w*100*4 / 1024**3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_FuE3xblS7p"
      },
      "source": [
        "## Hierarchical structure of images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNR9I2VplS7p"
      },
      "source": [
        "Images are made of elementary building blocks like *blobs* and *edges*. These can be combined to form more advanced shapes like *corners*. These in turn can lead to geometric shapes like *squares* etc. Following this reasoning one can eventually arrive at detailed real-life objects!\n",
        "\n",
        "An important thing to realise is that an *edge* can (and will) appear anywhere in an image! The fully-connected/linear layer can't take advantage of that because each of its weights is hardwired to a particular input pixel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD-jdM9rlS7p"
      },
      "source": [
        "## Convolutions explained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uz-yCMalS7q"
      },
      "source": [
        "- Convolutions walkthrough in [Excel](https://livebournemouthac-my.sharepoint.com/:x:/g/personal/mbudka_bournemouth_ac_uk/EfUMp0FVIaFJl0UboP4xb3gB8LyUPGeeV_yBTnWiBDBp4A?e=ueJMEu)\n",
        "- Yann Lecun's [paper on convolutions](http://www.max.hi-ho.ne.jp/kindo/sail_files/references/CV-Projects/lecun-89e.pdf) from **1989!!**\n",
        "- [LeNet-5 from 1998](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf) is essentially the relatively modern architecture of [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) from 2012"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CjQMgaMMZpTH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVueDY7JlS7q"
      },
      "source": [
        "# Simple CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZey_8g9lS7q"
      },
      "outputs": [],
      "source": [
        "net = nn.Sequential(\n",
        "    nn.Conv2d(in_channels=3,  out_channels=16, kernel_size=3, stride=1, padding=1), # 1 pixel padding with a 3x3 kernel preserves resolution\n",
        "    nn.LeakyReLU(inplace=True),\n",
        "    nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1), # for 5x5 kernel, padding=2 would preserve resolution\n",
        "    nn.LeakyReLU(inplace=True),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "    nn.LeakyReLU(inplace=True),\n",
        "    nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "    nn.LeakyReLU(inplace=True),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        ").cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWf01UUWlS7q"
      },
      "outputs": [],
      "source": [
        "xb = tc.randn((16, 3, 256, 256)).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mw9dmKkOlS7q"
      },
      "outputs": [],
      "source": [
        "out = net(xb)\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Cduoh-WlS7r"
      },
      "source": [
        "## Shapes step by step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81Jqx2NDlS7r"
      },
      "outputs": [],
      "source": [
        "xb.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVeRjSBllS7r"
      },
      "outputs": [],
      "source": [
        "o1 = net[0](xb)\n",
        "net[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEL_K64flS7r"
      },
      "outputs": [],
      "source": [
        "o1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHKhaFx-lS7r"
      },
      "outputs": [],
      "source": [
        "o2 = net[1](o1)\n",
        "net[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vp2hZEOblS7r"
      },
      "outputs": [],
      "source": [
        "o2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3txfVMflS7s"
      },
      "outputs": [],
      "source": [
        "o3 = net[2](o2)\n",
        "net[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mg-RLsV6lS7s"
      },
      "outputs": [],
      "source": [
        "o3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0wFAJgPlS7s"
      },
      "outputs": [],
      "source": [
        "o4 = net[3](o3)\n",
        "net[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCkPrn__lS7s"
      },
      "outputs": [],
      "source": [
        "o4.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlsP_BtXlS7s"
      },
      "outputs": [],
      "source": [
        "o5 = net[4](o4)\n",
        "net[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuBG8gm_lS7t"
      },
      "outputs": [],
      "source": [
        "o5.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxZKsNkwlS7t"
      },
      "outputs": [],
      "source": [
        "o6 = net[5](o5)\n",
        "net[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WGoSteflS7t"
      },
      "outputs": [],
      "source": [
        "o6.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPh6dJbulS7t"
      },
      "outputs": [],
      "source": [
        "o7 = net[6](o6)\n",
        "net[6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3QV_KsvlS7u"
      },
      "outputs": [],
      "source": [
        "o7.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BlXw7o2lS7u"
      },
      "outputs": [],
      "source": [
        "o8 = net[7](o7)\n",
        "net[7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WU9e499YlS7v"
      },
      "outputs": [],
      "source": [
        "o8.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBS0o6eIlS7v"
      },
      "outputs": [],
      "source": [
        "o9 = net[8](o8)\n",
        "net[8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAStVry3lS7v"
      },
      "outputs": [],
      "source": [
        "o9.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iu-XTpWalS7w"
      },
      "outputs": [],
      "source": [
        "o10 = net[9](o9)\n",
        "net[9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sv_hj8YvlS7w"
      },
      "outputs": [],
      "source": [
        "o10.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlU9tz87lS7w"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McyzlqoDlS7w"
      },
      "source": [
        "PyTorch comes with a number of common datasets out of the box. The full list is available [here](https://pytorch.org/vision/stable/datasets.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WP81EyenlS7x"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "from tempfile import TemporaryDirectory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCTvC4t9lS7x"
      },
      "outputs": [],
      "source": [
        "d = TemporaryDirectory(prefix='dataset')\n",
        "d.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12yrE2IulS7x"
      },
      "outputs": [],
      "source": [
        "tr_ds = datasets.CIFAR10(root=d.name, train=True, download=True, transform=transforms.ToTensor())\n",
        "tr_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgiLOAyflS7y"
      },
      "outputs": [],
      "source": [
        "val_ds = datasets.CIFAR10(root=d.name, train=False, download=True, transform=transforms.ToTensor())\n",
        "val_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABMjdGiRlS7y",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# without transform\n",
        "ds = datasets.CIFAR10(root=d.name, train=False, download=False)\n",
        "ds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYCYEif1lS7y"
      },
      "outputs": [],
      "source": [
        "tr_dl  = DataLoader(tr_ds,  batch_size=4, shuffle=True,  num_workers=2)\n",
        "val_dl = DataLoader(val_ds, batch_size=8, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOFrH9E9lS7y"
      },
      "outputs": [],
      "source": [
        "xb, yb = next(iter(tr_dl))\n",
        "xb.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lv93O63lS7y"
      },
      "outputs": [],
      "source": [
        "show_img(xb[2].numpy().transpose(1,2,0));  # transpose required to go from CxHxW to HxWxC (PyTorch is channel-first)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Utim2_0BlS7y"
      },
      "source": [
        "## Standardisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeKavWnblS7y"
      },
      "source": [
        "As before, we need to calculate per-channel pixel intensity mean ($\\mu$) and standard deviation ($\\sigma$) to be able to standardise/normalise our data. The problem is that for bigger datasets, you can't simply load it all to memory to calculate these two like we did with Fashion-MNIST. We will have to use a trick here instead!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-22uTvN0lS7y"
      },
      "source": [
        "The formulae for the mean and standard deviation that we have used before are:\n",
        "\n",
        "$\\mu ={\\frac {1}{N}}\\sum _{i=1}^{N}x_{i}$\n",
        "\n",
        "$\\sigma ={\\sqrt {{\\frac {1}{N}}\\sum _{i=1}^{N}(x_{i}-\\mu )^{2}}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKsssNaAlS7y"
      },
      "source": [
        "The issue is that in order to calculate $\\sigma$, we need to know $\\mu$, so a naïve approach will require **two passess** over the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHrOUyTklS7z"
      },
      "source": [
        "We can however take advantage of the following (see [Wikipedia](https://en.wikipedia.org/wiki/Standard_deviation#Definition_of_population_values)), where $\\operatorname {E} [X]=\\mu$:\n",
        "\n",
        "${\\displaystyle {\\begin{aligned}\\sigma &={\\sqrt {\\operatorname {E} [(X-\\mu )^{2}]}}\\\\&={\\sqrt {\\operatorname {E} [X^{2}]+\\operatorname {E} [-2\\mu X]+\\operatorname {E} [\\mu ^{2}]}}\\\\&={\\sqrt {\\operatorname {E} [X^{2}]-2\\mu \\operatorname {E} [X]+\\mu ^{2}}}\\\\&={\\sqrt {\\operatorname {E} [X^{2}]-2\\mu ^{2}+\\mu ^{2}}}\\\\&={\\sqrt {\\operatorname {E} [X^{2}]-\\mu ^{2}}}\\\\&={\\sqrt {\\operatorname {E} [X^{2}]-(\\operatorname {E} [X])^{2}}}\\end{aligned}}}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgP8aAOclS7z"
      },
      "source": [
        "The above calculation in [Excel](https://livebournemouthac-my.sharepoint.com/:x:/g/personal/mbudka_bournemouth_ac_uk/EbEmpdAesrZHkuHg4ijDIwcBz2ILj_mcGOeEy8Z1rwqd1w?e=mZ7XBh)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GL8mI-m1lS7z"
      },
      "outputs": [],
      "source": [
        "def get_stats(dl):\n",
        "    cnt, csum, csum_sq = tc.zeros(1), tc.zeros(3), tc.zeros(3)  # accumulators; 3d because 3 colour channels\n",
        "\n",
        "    for xb,_ in tqdm(dl):\n",
        "        cnt += xb.shape[0]*xb.shape[2]*xb.shape[3]  # number of pixels per channel\n",
        "        csum += xb.sum(dim=(0,2,3))                 # this gives 3 numbers i.e. sums of pixel intensities per each colour channel\n",
        "        csum_sq += (xb**2).sum(dim=(0,2,3))         # ditto\n",
        "\n",
        "    μ = csum / cnt\n",
        "    σ = (csum_sq / cnt - μ**2).sqrt()\n",
        "    return μ, σ\n",
        "\n",
        "data_stats = get_stats(tr_dl)\n",
        "data_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dI-w3raUlS7z"
      },
      "outputs": [],
      "source": [
        "transf = transforms.Compose([           # compose mutiple transforms; could use nn.Sequential() here instead of transforms.Compose()\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(*data_stats)   # equivalent to transforms.Normalize(stl10_stats[0], stl10_stats[1])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ESsb5OJlS7z"
      },
      "outputs": [],
      "source": [
        "# tr_ds  = datasets.STL10(root=d.name, split='train', download=True, transform=transf)\n",
        "# val_ds = datasets.STL10(root=d.name, split='test',  download=True, transform=transf)\n",
        "\n",
        "tr_ds  = datasets.CIFAR10(root=d.name, train=True, download=True, transform=transf)\n",
        "val_ds = datasets.CIFAR10(root=d.name, train=False,  download=True, transform=transf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iafLm96zlS7z"
      },
      "outputs": [],
      "source": [
        "bs = 8\n",
        "tr_dl  = DataLoader(tr_ds,  batch_size=bs,   shuffle=True,  num_workers=2)\n",
        "val_dl = DataLoader(val_ds, batch_size=2*bs, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCcSaWbYlS7z"
      },
      "outputs": [],
      "source": [
        "get_stats(tr_dl), get_stats(val_dl)  # sanity checks - we expect them to now be 0-mean, 1-std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUkZi7y6lS70"
      },
      "outputs": [],
      "source": [
        "xb, yb = next(iter(tr_dl))\n",
        "show_img(xb[1].numpy().transpose(1,2,0));\n",
        "xb[0].min(), xb[0].max(), xb[0].mean(), xb[0].std()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjov9u7VlS70"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-zZr952lS70"
      },
      "source": [
        "## Network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5HzAg4OlS70"
      },
      "outputs": [],
      "source": [
        "# input: [bs,3,h,w] - this network will accept *any* input resolution\n",
        "net = nn.Sequential(\n",
        "    nn.Conv2d(in_channels=3,  out_channels=16, kernel_size=3, stride=1, padding=1), nn.LeakyReLU(), # [bs,16,h,w]\n",
        "    nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1), nn.LeakyReLU(), # [bs,16,h,w]\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),                                                          # [bs,16,h/2,w/2]\n",
        "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1), nn.LeakyReLU(), # [bs,32,h/2,w/2]\n",
        "    nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1), nn.LeakyReLU(), # [bs,32,h/2,w/2]\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),                                                          # [bs,32,h/4,w/4]\n",
        "    # nn.Flatten(), nn.Linear(32*24*24, 10) # required for classification but this will tie the network to a fixed input resolution\n",
        ").cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jt-aECjGlS70"
      },
      "outputs": [],
      "source": [
        "xb, yb = next(iter(tr_dl))\n",
        "xb.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoMUrpw_lS70"
      },
      "outputs": [],
      "source": [
        "o = net(xb.cuda())\n",
        "o.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ybrj5AElS70"
      },
      "outputs": [],
      "source": [
        "net1 = nn.Sequential(\n",
        "    *net[:-1],                   # use all the layers from 'net' (unpacking trick) without the last MaxPool2d\n",
        "    nn.AdaptiveAvgPool2d((4,4))  # keras/tensorflow didn't have it until very recently!\n",
        ")\n",
        "net1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPfPh6KQlS70"
      },
      "outputs": [],
      "source": [
        "net1(xb.cuda()).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJntBlUWlS70",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "dummy = tc.randn((16, 3, 256, 256)).cuda()\n",
        "net(dummy).shape, net1(dummy).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7E-4wffblS71"
      },
      "outputs": [],
      "source": [
        "dummy = tc.randn((16, 3, 128, 128)).cuda()\n",
        "net(dummy).shape, net1(dummy).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MoHbQZ8lS71"
      },
      "outputs": [],
      "source": [
        "dummy = tc.randn((16, 3, 256, 128)).cuda()\n",
        "net(dummy).shape, net1(dummy).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooUE66yflS71"
      },
      "outputs": [],
      "source": [
        "# final network with classification head\n",
        "net2 = nn.Sequential(\n",
        "    *net[:-1],\n",
        "    nn.AdaptiveAvgPool2d((4,4)),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(32*4*4,10)\n",
        ").cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "od1HGDQilS71"
      },
      "outputs": [],
      "source": [
        "net2(dummy).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Upafe-q1lS71"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEiO8hVglS71"
      },
      "outputs": [],
      "source": [
        "from torch.amp import GradScaler, autocast\n",
        "\n",
        "def fit(net, tr_dl, val_dl, loss=nn.CrossEntropyLoss(), epochs=3, lr=3e-3, wd=1e-3):\n",
        "\n",
        "    Ltr_hist, Lval_hist = [], []\n",
        "\n",
        "    scaler = GradScaler()  # for mixed-precision training\n",
        "\n",
        "    opt = optim.AdamW(net.parameters(), lr=lr, weight_decay=wd)\n",
        "    for epoch in trange(epochs):\n",
        "        L = []\n",
        "        dl = iter(tr_dl)\n",
        "        for xb, yb in tqdm(dl, leave=False):\n",
        "            xb, yb = xb.cuda(), yb.cuda()\n",
        "            with autocast(device_type='cuda'):  # for mixed-precision training\n",
        "                y_ = net(xb)\n",
        "                l = loss(y_, yb)\n",
        "            opt.zero_grad()\n",
        "            scaler.scale(l).backward()  # previously l.backward()\n",
        "            scaler.step(opt)            # previously opt.step()\n",
        "            scaler.update()\n",
        "            L.append(l.detach().cpu().numpy())\n",
        "\n",
        "        Lval, Aval = [], []\n",
        "        with tc.no_grad():\n",
        "            for xb, yb in tqdm(iter(val_dl), leave=False):\n",
        "                xb, yb = xb.cuda(), yb.cuda()\n",
        "                with autocast(device_type='cuda'):\n",
        "                    y_ = net(xb)\n",
        "                    l = loss(y_, yb)\n",
        "                Lval.append(l.detach().cpu().numpy())\n",
        "                Aval.append((y_.max(dim=1)[1] == yb).float().mean().cpu().numpy())\n",
        "\n",
        "        Ltr_hist.append(np.mean(L))\n",
        "        Lval_hist.append(np.mean(Lval))\n",
        "        print(f'training loss: {np.mean(L):0.4f}\\tvalidation loss: {np.mean(Lval):0.4f}\\tvalidation accuracy: {np.mean(Aval):0.2f}')\n",
        "    return Ltr_hist, Lval_hist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PxDhuSilS71"
      },
      "outputs": [],
      "source": [
        "Ltr_hist, Lval_hist = fit(net2, tr_dl, val_dl, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MK-32EqQlS71"
      },
      "outputs": [],
      "source": [
        "_,ax = plt.subplots(1,1,figsize=(20,4))\n",
        "ax.plot(1+np.arange(len(Ltr_hist)),Ltr_hist)\n",
        "ax.plot(1+np.arange(len(Lval_hist)),Lval_hist)\n",
        "ax.grid('on')\n",
        "ax.set_xlim(left=1, right=len(Ltr_hist))\n",
        "ax.legend(['training loss', 'validation loss']);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW_4ffmVlS71"
      },
      "source": [
        "# Homework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0blUbUK9lS71"
      },
      "source": [
        "## For all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCOzU6CwlS71"
      },
      "source": [
        "Train the neural network we have used in this notebook for maximum validation accuracy. Play with different values of the `learning rate` and `epochs`. Write down your results every time you train the network (i.e. for `lr=xx` and `epochs==yy`, `accuracy==zz`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Szkzq3aNlS72"
      },
      "source": [
        "## For volunteers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leTdwW_zlS72"
      },
      "source": [
        "Implement 2D convolution from scratch using loops."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTdjvPpplS72"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "328px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": "160"
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}